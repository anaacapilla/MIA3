{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RepasoKeras_APIFuncional.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anaacapilla/MIA3/blob/main/RepasoKeras_APIFuncional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ1tIWQ3soHE"
      },
      "source": [
        "# Keras\n",
        "\n",
        "Keras es una librería construída para el prototipado rápido de modelos de deep learning. Las ventajas de Keras frente a otros frameworks de deep learning son obvios:\n",
        "\n",
        "- Rápido prototipado (entrenamiento y evaluación) de modelos de deep learning.\n",
        "\n",
        "- Posee una api sencilla con la que se pueden añadir estructuras complejas en redes de neuronas (capas).\n",
        "\n",
        "- Se integra con las herramientas de tensorflow de forma nativa.\n",
        "\n",
        "Keras permite construir modelos utilizando diferentes tipos de api (Application Porgram Interface). Las distintas apis tienen sus ventajas e inconvenientes, en esta clase vamos a estudiar la api secuencial y la api funcional de Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE6_0KlCzQBg"
      },
      "source": [
        "# Keras Sequential API\n",
        "\n",
        "La api secuencial de Keras permite construir modelos añadiendo capas en forma de secuencia. Su uso es muy directo siguiendo los siguientes pasos:\n",
        "\n",
        "- Definimos el modelo utilizando la clase Sequential.\n",
        "\n",
        "- Añadimos capas al modelo utilizando el método .add()\n",
        "\n",
        "- Comppilamos el modelo utilizando el método .compile()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqkkRezH2Y-Y"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrkI4arDzPVX"
      },
      "source": [
        "# Ejemplo - dataset iris tiene 3 clases y por eso la última capa tiene 3 neuronas\n",
        "dataset = sns.load_dataset(\"iris\")\n",
        "model = keras.models.Sequential()\n",
        "layer_1 = keras.layers.Dense(10, activation=\"relu\")\n",
        "output = keras.layers.Dense(3, activation=\"softmax\")\n",
        "model.add(layer_1)\n",
        "model.add(output)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2l_zLDVFZem",
        "outputId": "d85e7113-cea9-41c8-9f24-30e85e2fd457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(model)\n",
        "type(layer_1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.layers.core.dense.Dense"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sPqmTkl3Ld8"
      },
      "source": [
        "X = dataset.iloc[:,:-1]\n",
        "Y = dataset.iloc[:,-1:]\n",
        "Y_dummies = pd.get_dummies(Y)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y_dummies)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se34peYnQQDS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "712f3c0c-c08a-48b6-f0d8-5f6c9531de2e"
      },
      "source": [
        "X"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width\n",
              "0             5.1          3.5           1.4          0.2\n",
              "1             4.9          3.0           1.4          0.2\n",
              "2             4.7          3.2           1.3          0.2\n",
              "3             4.6          3.1           1.5          0.2\n",
              "4             5.0          3.6           1.4          0.2\n",
              "..            ...          ...           ...          ...\n",
              "145           6.7          3.0           5.2          2.3\n",
              "146           6.3          2.5           5.0          1.9\n",
              "147           6.5          3.0           5.2          2.0\n",
              "148           6.2          3.4           5.4          2.3\n",
              "149           5.9          3.0           5.1          1.8\n",
              "\n",
              "[150 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBH3c6I65X8_",
        "outputId": "e0947693-9e72-4248-eec0-efc5b5b7cc65"
      },
      "source": [
        "model.fit(X_train, Y_train, epochs=300)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "4/4 [==============================] - 1s 4ms/step - loss: 3.3109\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 3.2082\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.1008\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.0023\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.8969\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.8068\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.7031\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.5988\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5115\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.4203\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.3293\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2468\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.1650\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.0834\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.0096\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.9396\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.8732\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.8100\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.7571\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.7086\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.6635\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.6221\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.5870\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.5531\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.5201\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4908\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4644\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4413\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4182\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3968\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3748\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3557\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.3375\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3189\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3008\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2831\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2658\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2490\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2317\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2152\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1990\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1824\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1668\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1508\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1354\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1197\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1055\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0898\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0747\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0602\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0457\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0312\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0189\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0037\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9906\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9769\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9640\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9514\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9387\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9265\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9142\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9024\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8910\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8796\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8683\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8577\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8464\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8361\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8259\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8159\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8056\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7963\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7867\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7780\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7695\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7602\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7523\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7436\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7358\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7279\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7208\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7127\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7058\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6985\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6914\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6847\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6779\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6715\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6650\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6589\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6525\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6471\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6409\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6355\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6302\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6245\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6194\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6141\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6087\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6037\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5987\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5939\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5892\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5842\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5801\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5752\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5708\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5669\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5627\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5581\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5539\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5501\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5462\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5426\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5383\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5346\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5309\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5272\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5237\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5201\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5165\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5132\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5099\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5065\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5038\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5002\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4968\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4937\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4906\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4876\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4855\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4818\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4794\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4761\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4734\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4701\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4676\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4656\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4626\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4601\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4576\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4550\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4524\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4498\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4474\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4451\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4428\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4403\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4384\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4359\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4340\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4312\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4291\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4267\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4245\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4224\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4203\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4185\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4163\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4140\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4119\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4101\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4076\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4058\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4055\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4026\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4005\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3981\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3965\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3947\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3924\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3908\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3890\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3869\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3850\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3833\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3815\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3798\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3783\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3767\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3746\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3741\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3715\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3696\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3676\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3661\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3645\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3631\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3618\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3595\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3583\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3564\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3551\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3534\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3517\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3505\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3488\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3475\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3458\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3445\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3430\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3414\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3399\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3384\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3369\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3356\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3341\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3330\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3318\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3302\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3285\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3273\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3256\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3255\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3234\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3219\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3206\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3189\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3179\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3171\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3158\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3139\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3124\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3118\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3108\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3091\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3084\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3063\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3049\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3041\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3030\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3014\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3003\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2991\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2981\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2966\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2954\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2950\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2932\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2922\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2921\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2902\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2889\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2875\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2869\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2857\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2846\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2834\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2821\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2810\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2799\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2791\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2778\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2768\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2756\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2749\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2747\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2733\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2717\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2707\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2694\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2686\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2679\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2670\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2658\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2645\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2639\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2630\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2620\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2607\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2595\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2591\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2580\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2572\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2566\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2551\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2543\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2535\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2526\n",
            "Epoch 280/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2517\n",
            "Epoch 281/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2505\n",
            "Epoch 282/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2496\n",
            "Epoch 283/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2490\n",
            "Epoch 284/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2477\n",
            "Epoch 285/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2467\n",
            "Epoch 286/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2462\n",
            "Epoch 287/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2455\n",
            "Epoch 288/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2448\n",
            "Epoch 289/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2436\n",
            "Epoch 290/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2431\n",
            "Epoch 291/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2418\n",
            "Epoch 292/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2411\n",
            "Epoch 293/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2403\n",
            "Epoch 294/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2393\n",
            "Epoch 295/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2384\n",
            "Epoch 296/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2376\n",
            "Epoch 297/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2368\n",
            "Epoch 298/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2360\n",
            "Epoch 299/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2353\n",
            "Epoch 300/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2346\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb981e80110>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65HyLVmZ53Mg",
        "outputId": "cc5792b9-faf3-4cc6-d27b-d979aa6b3c41"
      },
      "source": [
        "# Realizar predicción\n",
        "model.predict(X_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.60615218e-01, 3.78754474e-02, 1.50926062e-03],\n",
              "       [8.78277002e-04, 2.52108246e-01, 7.47013390e-01],\n",
              "       [1.48395021e-02, 6.75350070e-01, 3.09810519e-01],\n",
              "       [9.66610432e-01, 3.22854258e-02, 1.10414787e-03],\n",
              "       [2.11399188e-03, 4.18694466e-01, 5.79191566e-01],\n",
              "       [6.59505418e-03, 5.78544736e-01, 4.14860189e-01],\n",
              "       [9.31521595e-01, 6.49548322e-02, 3.52360122e-03],\n",
              "       [2.70786192e-02, 7.10908055e-01, 2.62013257e-01],\n",
              "       [1.37673346e-02, 7.09273279e-01, 2.76959330e-01],\n",
              "       [3.33259478e-02, 7.94196665e-01, 1.72477379e-01],\n",
              "       [4.88466758e-04, 2.25281790e-01, 7.74229705e-01],\n",
              "       [7.62418029e-04, 1.93032697e-01, 8.06204915e-01],\n",
              "       [1.73567189e-03, 2.87153542e-01, 7.11110830e-01],\n",
              "       [2.94716726e-03, 4.24502283e-01, 5.72550595e-01],\n",
              "       [2.83088710e-04, 1.40344679e-01, 8.59372199e-01],\n",
              "       [2.29276549e-02, 7.90991247e-01, 1.86081097e-01],\n",
              "       [1.50855342e-02, 7.61262178e-01, 2.23652273e-01],\n",
              "       [9.59989071e-01, 3.84324789e-02, 1.57845602e-03],\n",
              "       [9.60693002e-01, 3.78817990e-02, 1.42521283e-03],\n",
              "       [3.09356600e-02, 7.94116259e-01, 1.74948126e-01],\n",
              "       [1.03814251e-04, 9.31910723e-02, 9.06705081e-01],\n",
              "       [9.46475625e-01, 5.13326488e-02, 2.19167117e-03],\n",
              "       [2.71688274e-04, 1.61017761e-01, 8.38710487e-01],\n",
              "       [8.80235583e-02, 7.76277900e-01, 1.35698557e-01],\n",
              "       [9.43177164e-01, 5.41850179e-02, 2.63788109e-03],\n",
              "       [1.43737416e-03, 5.18098116e-01, 4.80464518e-01],\n",
              "       [3.16578709e-02, 7.76935697e-01, 1.91406518e-01],\n",
              "       [1.15755294e-03, 1.73685655e-01, 8.25156868e-01],\n",
              "       [9.67235386e-01, 3.16670947e-02, 1.09758857e-03],\n",
              "       [2.76366307e-04, 1.30056903e-01, 8.69666755e-01],\n",
              "       [9.50651765e-01, 4.74756286e-02, 1.87259063e-03],\n",
              "       [8.03429110e-04, 2.00528666e-01, 7.98667908e-01],\n",
              "       [9.58397806e-01, 4.00071181e-02, 1.59507664e-03],\n",
              "       [4.44650592e-04, 3.25795352e-01, 6.73759937e-01],\n",
              "       [2.47224147e-04, 1.00055516e-01, 8.99697244e-01],\n",
              "       [2.11845222e-03, 2.57740676e-01, 7.40140975e-01],\n",
              "       [3.17739462e-03, 3.23327273e-01, 6.73495352e-01],\n",
              "       [9.60274637e-01, 3.80848646e-02, 1.64054241e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iDZAFdO7oWQ"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "Entrenad un modelo de 3 capas densas utilizando la api secuencial de Keras para el dataset penguins. El objetivo es clasificar el sexo del pingüino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDN2exgkIsHy",
        "outputId": "9e907e1f-e964-4319-cc59-de912c57fa9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>36.7</td>\n",
              "      <td>19.3</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3450.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.3</td>\n",
              "      <td>20.6</td>\n",
              "      <td>190.0</td>\n",
              "      <td>3650.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>Gentoo</td>\n",
              "      <td>Biscoe</td>\n",
              "      <td>47.2</td>\n",
              "      <td>13.7</td>\n",
              "      <td>214.0</td>\n",
              "      <td>4925.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>Gentoo</td>\n",
              "      <td>Biscoe</td>\n",
              "      <td>46.8</td>\n",
              "      <td>14.3</td>\n",
              "      <td>215.0</td>\n",
              "      <td>4850.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>Gentoo</td>\n",
              "      <td>Biscoe</td>\n",
              "      <td>50.4</td>\n",
              "      <td>15.7</td>\n",
              "      <td>222.0</td>\n",
              "      <td>5750.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>Gentoo</td>\n",
              "      <td>Biscoe</td>\n",
              "      <td>45.2</td>\n",
              "      <td>14.8</td>\n",
              "      <td>212.0</td>\n",
              "      <td>5200.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>Gentoo</td>\n",
              "      <td>Biscoe</td>\n",
              "      <td>49.9</td>\n",
              "      <td>16.1</td>\n",
              "      <td>213.0</td>\n",
              "      <td>5400.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>333 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    species     island  bill_length_mm  ...  flipper_length_mm  body_mass_g     sex\n",
              "0    Adelie  Torgersen            39.1  ...              181.0       3750.0    Male\n",
              "1    Adelie  Torgersen            39.5  ...              186.0       3800.0  Female\n",
              "2    Adelie  Torgersen            40.3  ...              195.0       3250.0  Female\n",
              "4    Adelie  Torgersen            36.7  ...              193.0       3450.0  Female\n",
              "5    Adelie  Torgersen            39.3  ...              190.0       3650.0    Male\n",
              "..      ...        ...             ...  ...                ...          ...     ...\n",
              "338  Gentoo     Biscoe            47.2  ...              214.0       4925.0  Female\n",
              "340  Gentoo     Biscoe            46.8  ...              215.0       4850.0  Female\n",
              "341  Gentoo     Biscoe            50.4  ...              222.0       5750.0    Male\n",
              "342  Gentoo     Biscoe            45.2  ...              212.0       5200.0  Female\n",
              "343  Gentoo     Biscoe            49.9  ...              213.0       5400.0    Male\n",
              "\n",
              "[333 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC2RG3zaIZHA",
        "outputId": "b351d51e-5d1a-4829-bc57-803ce28833c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset[\"species\"].value_counts()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adelie       146\n",
              "Gentoo       119\n",
              "Chinstrap     68\n",
              "Name: species, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYJz5BkcIY-r",
        "outputId": "4127a89f-2b37-461a-da26-47857a78b1a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>species_Adelie</th>\n",
              "      <th>species_Chinstrap</th>\n",
              "      <th>species_Gentoo</th>\n",
              "      <th>island_Biscoe</th>\n",
              "      <th>island_Dream</th>\n",
              "      <th>island_Torgersen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36.7</td>\n",
              "      <td>19.3</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3450.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>39.3</td>\n",
              "      <td>20.6</td>\n",
              "      <td>190.0</td>\n",
              "      <td>3650.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bill_length_mm  bill_depth_mm  ...  island_Dream  island_Torgersen\n",
              "0            39.1           18.7  ...             0                 1\n",
              "1            39.5           17.4  ...             0                 1\n",
              "2            40.3           18.0  ...             0                 1\n",
              "4            36.7           19.3  ...             0                 1\n",
              "5            39.3           20.6  ...             0                 1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu18mU3MQ9qs"
      },
      "source": [
        "dataset = sns.load_dataset(\"penguins\")\n",
        "dataset.head(10)\n",
        "dataset.dropna(inplace=True)\n",
        "X = pd.get_dummies(dataset.iloc[:,:-1])\n",
        "Y = pd.get_dummies(dataset.iloc[:,-1:])\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbInp8YLJO_y"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "\n",
        "layer_1 = keras.layers.Dense(9,activation=\"relu\")\n",
        "layer_2 = keras.layers.Dense(7,activation=\"relu\")\n",
        "layer_3 = keras.layers.Dense(5,activation=\"relu\")\n",
        "output = keras.layers.Dense(2,activation=\"softmax\")\n",
        "\n",
        "model.add(layer_1)\n",
        "model.add(layer_2)\n",
        "model.add(layer_3)\n",
        "model.add(output)\n",
        "\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhNLJgZMSgNo"
      },
      "source": [
        "# model = keras.models.Sequential()\n",
        "# layer_1 = keras.layers.Dense(9, activation=\"relu\")\n",
        "# layer_2 = keras.layers.Dense(7, activation=\"relu\")\n",
        "# layer_3 = keras.layers.Dense(5, activation=\"relu\")\n",
        "# output = keras.layers.Dense(2, activation=\"softmax\")\n",
        "# model.add(layer_1)\n",
        "# model.add(layer_2)\n",
        "# model.add(layer_3)\n",
        "# model.add(output)\n",
        "# model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvys6H0KS_tB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df237393-0464-4b77-8dac-29ab72dbb28e"
      },
      "source": [
        "model.fit(X_train, Y_train, epochs=300)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 258.2654\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 161.0601\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 63.0589\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.3425\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2445\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5144\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4532\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0381\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0948\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8126\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7256\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7320\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7112\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6942\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6957\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6953\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6958\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7078\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6975\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6933\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6934\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6969\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6965\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6975\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6956\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6982\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7000\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6975\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6960\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6948\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6946\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6953\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7056\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6953\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6944\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6958\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6961\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6945\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6952\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7030\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7036\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7034\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6982\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7017\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7000\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6937\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7008\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6999\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7011\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7066\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6972\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7006\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7032\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7121\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7047\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7264\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7081\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6904\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7301\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7014\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7508\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7144\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7288\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6841\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6965\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6957\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6931\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6935\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7060\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6903\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6913\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6901\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7070\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7107\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7119\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6998\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6951\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6950\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6838\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7022\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6965\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6889\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7014\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7063\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6862\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6886\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7016\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6945\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6942\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6936\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7148\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7026\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6900\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6889\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7055\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6942\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7187\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7366\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6972\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7002\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6874\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6885\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6999\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7161\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6837\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6849\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6829\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6834\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6843\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6828\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6847\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6877\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6908\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6857\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7071\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6749\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6890\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6861\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6853\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6936\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6878\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7132\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7019\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6893\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6954\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6939\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6811\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6990\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7008\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7651\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7645\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7315\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7042\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6938\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7190\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6820\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6822\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6789\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6800\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6867\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6784\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6814\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6850\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6876\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7151\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6867\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6941\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6885\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6953\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7051\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6783\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6836\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6862\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7091\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7247\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7159\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6761\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6818\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6964\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7016\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7255\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7194\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7014\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6931\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6807\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6741\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6771\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6893\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6869\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6867\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6801\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6982\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6861\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6774\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7044\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6707\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6812\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7261\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7150\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7067\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6890\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6817\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6895\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6932\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7129\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7039\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6757\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6845\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6721\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6788\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6701\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6933\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7594\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7068\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6749\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6925\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7066\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6765\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6843\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6775\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7173\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6881\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7035\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6671\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6729\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6713\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6746\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6736\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6708\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6743\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6908\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6917\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7250\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6963\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6765\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6979\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7275\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7074\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6895\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6666\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6771\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6971\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6849\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6613\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6774\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6641\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6642\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6754\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6686\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6699\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6715\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6664\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6676\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6737\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6869\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6691\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6685\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6668\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7023\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7010\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6870\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6909\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6767\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6681\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6722\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6668\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6642\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6771\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6783\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6971\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6959\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6956\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6752\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6703\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6706\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6667\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6701\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6740\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6989\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6679\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6811\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7120\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6772\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6586\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6723\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6619\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6610\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6670\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6830\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6868\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6813\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6663\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6591\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6906\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6708\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6618\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6627\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6703\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6613\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6600\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6578\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6738\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6758\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6938\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6956\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6725\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6826\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6751\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6586\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6569\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6594\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6616\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6559\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6593\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6572\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6556\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6556\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6616\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6792\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6576\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb97af3a910>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLCbHARt7xdw"
      },
      "source": [
        "# Eliminar capas de un modelo secuencial.\n",
        "\n",
        "Es posible eliminar capas de un modelo secuencial utilizando el método .pop()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhFdqVoEP4QU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a1a2cb-1a7e-4bf6-d843-454bc9f4bae0"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.core.dense.Dense at 0x7fb97af30110>,\n",
              " <keras.layers.core.dense.Dense at 0x7fb97af0d390>,\n",
              " <keras.layers.core.dense.Dense at 0x7fb97b133350>,\n",
              " <keras.layers.core.dense.Dense at 0x7fb97afb8cd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5s3QkcCGf2Y",
        "outputId": "cf097b47-2f91-49ff-cd11-f20f484bf752",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.layers[0] #me permite acceder a cada capa\n",
        "model.layers[0].weights # me permite acceder a los pesos de la capa\n",
        "model.layers[0].weights[0] # me permite acceder a los pesos de la capa\n",
        "model.layers[0].weights[0].numpy() # me permite acceder a los pesos de la capa"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.251183  ,  0.268822  , -0.48547855,  0.11678526,  0.0216338 ,\n",
              "         0.43667406, -0.33964115,  0.20797886, -0.46955025],\n",
              "       [-0.44327566, -0.03353351,  0.04824114,  0.12319595,  0.39954454,\n",
              "         0.16159989,  0.27341983, -0.36711666,  0.05543947],\n",
              "       [-0.33700705,  0.50030774, -0.1026465 ,  0.3547629 , -0.04148906,\n",
              "         0.20883434, -0.07613142, -0.33252096, -0.00656646],\n",
              "       [ 0.20512109,  0.0675953 , -0.3172649 , -0.0285286 , -0.34891963,\n",
              "         0.45385408,  0.06662396,  0.26978132, -0.3967722 ],\n",
              "       [-0.15100887,  0.05060093, -0.53913057, -0.10433655, -0.46658018,\n",
              "         0.12563694,  0.07021558,  0.57785684, -0.25986388],\n",
              "       [-0.04975721, -0.26356432,  0.18777007, -0.51678365, -0.41685805,\n",
              "         0.14815813, -0.00765311,  0.15237996, -0.4952809 ],\n",
              "       [ 0.47664997, -0.13929497,  0.08011115, -0.09361801, -0.3683412 ,\n",
              "         0.48070168, -0.5297288 ,  0.5703738 ,  0.324489  ],\n",
              "       [ 0.42283598,  0.31413656, -0.21051905, -0.05528578,  0.02459908,\n",
              "        -0.10426936, -0.01602935,  0.00498001,  0.4928959 ],\n",
              "       [-0.10902231,  0.07759102,  0.1680215 ,  0.4137372 ,  0.50165707,\n",
              "        -0.1605278 , -0.4512834 , -0.04054734,  0.22247899],\n",
              "       [-0.19521925, -0.4822096 , -0.45479438, -0.5530567 , -0.0395686 ,\n",
              "        -0.18422067,  0.01273317, -0.02896595,  0.3342383 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4a4s7_V6dRW"
      },
      "source": [
        "model.pop() # Elimina la última capa"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxVQuny5VoRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ffb26d3-a4ce-4e3d-ccaa-e565695e18ac"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.core.dense.Dense at 0x7fb97af30110>,\n",
              " <keras.layers.core.dense.Dense at 0x7fb97af0d390>,\n",
              " <keras.layers.core.dense.Dense at 0x7fb97b133350>]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dce5l1pnQg7o"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLykN8GY8SZI",
        "outputId": "ebe51bd1-295a-41fd-c43d-552d5a506045"
      },
      "source": [
        "model.predict(X_train).shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(249, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcllTz2Q8UH_",
        "outputId": "612cc4c2-2157-4ea4-e7d9-1c875f39f8b7"
      },
      "source": [
        "model.predict(X_train)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0.     ,   0.     , 595.1528 ,   0.     ,   0.     ],\n",
              "       [  0.     ,   0.     , 591.24005,   0.     ,   0.     ],\n",
              "       [  0.     ,   0.     , 522.7814 ,   0.     ,   0.     ],\n",
              "       ...,\n",
              "       [  0.     ,   0.     , 432.70264,   0.     ,   0.     ],\n",
              "       [  0.     ,   0.     , 668.64014,   0.     ,   0.     ],\n",
              "       [  0.     ,   0.     , 517.60376,   0.     ,   0.     ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HgsPWzi9OMr"
      },
      "source": [
        "# API Funcional\n",
        "\n",
        "La api funcional de Keras plantea construir un modelo mediante funciones. Las capas definidas en esta api se estructuran como funciones de Python cuya entrada es la salida de la capa anterior. Para construir un modelo utilizando la API Funcional de Keras hay que seguir los siguientes pasos:\n",
        "\n",
        "- Definir la entrada con keras.layers.Input()\n",
        "- Definir las capas de keras.layers\n",
        "- Definir el modelo con keras.models.Model()\n",
        "- Compilar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZgVO8rk_5Rg"
      },
      "source": [
        "dataset = sns.load_dataset(\"iris\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSPGU3xlPqmP",
        "outputId": "d531378e-77be-435d-a202-3a85a2f574a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "dataset.head(3)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myGihdhu9NhT"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(4,)) # 4 caracteristicas\n",
        "layer_1_def = keras.layers.Dense(5, activation=\"relu\")\n",
        "output_def = keras.layers.Dense(3, activation=\"softmax\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMHeyNcKYclB"
      },
      "source": [
        "layer_1 = layer_1_def(input_layer)\n",
        "output = output_def(layer_1)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFuqifG3YTtx"
      },
      "source": [
        "model = keras.Model(inputs=input_layer, outputs=output)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyqA_4wR8ZD3"
      },
      "source": [
        "X = dataset.iloc[:,:-1]\n",
        "Y = dataset.iloc[:,-1:]\n",
        "Y_dummies = pd.get_dummies(Y)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y_dummies)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUi4MMH2_9hI",
        "outputId": "80fd014c-9951-4865-99ae-dd969cfb36f6"
      },
      "source": [
        "model.fit(X_train,Y_train, epochs=200)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3085\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2865\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2648\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.2441\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.2242\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2037\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1849\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1682\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1524\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1374\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1240\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1100\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0963\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0858\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0748\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0641\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0537\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0437\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0341\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0247\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0156\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0066\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9983\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9893\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9812\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9727\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9646\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9571\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9493\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9417\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9272\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9201\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9128\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9060\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8992\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8926\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8858\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8795\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8730\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8667\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8606\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8544\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8485\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8429\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8369\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8313\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8259\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8204\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8150\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8098\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8047\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7996\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7948\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7900\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7855\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7810\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7765\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7723\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7681\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7639\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7599\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7561\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7521\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7483\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7446\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7410\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7376\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7341\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7306\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7273\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.7240\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7209\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7178\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7147\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7117\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7088\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7059\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7030\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7004\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6975\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6949\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6922\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6897\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6872\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6847\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6824\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6800\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6777\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6755\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6732\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6710\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6688\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6668\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6647\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6627\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6607\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6587\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6568\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6550\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6532\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6514\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6496\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6479\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6461\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6445\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6428\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6412\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6396\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6381\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6365\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6350\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6336\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6321\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6306\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6293\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6279\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6265\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6251\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6238\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6224\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6212\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6198\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6186\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6173\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6162\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6148\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6136\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6124\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6112\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6101\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6089\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6077\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6065\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6054\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6043\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6031\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6020\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6009\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5998\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5987\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5977\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5966\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5955\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5946\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5934\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5924\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5914\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5903\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5893\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5883\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5873\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5863\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5853\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5843\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5833\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5823\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5814\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5804\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5795\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5785\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5776\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5767\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5757\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5748\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5739\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5729\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5721\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5711\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5702\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5694\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5685\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5676\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5668\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5659\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5651\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5642\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5633\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5624\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5616\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5607\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5599\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5591\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5582\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5574\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5566\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5558\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5550\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5541\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5533\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5525\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5517\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5509\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5501\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5493\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5485\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5477\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5469\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5462\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5454\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb97ade0990>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8CFBzwKBEYH"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "Construid un modelo de 3 capas densas utilizando la API Funcional de Keras sobre el dataset penguins."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a12hrOu0BkH3"
      },
      "source": [
        "# Acceder a las capas intermedias de un modelo\n",
        "\n",
        "A veces es interesante poder acceder a la salida de una capa intermedia de un modelo entrenado previamente. Para ello es necesario construir un nuevo modelo definiendo una nueva salida.\n",
        "\n",
        "Una vez definida la nueva salida es posible aplicar análisis dimensional (comprobar las dimensiones de la salida) para comprender más acerca del modelo y si hemos elegido la capa correcta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqJ9opzmZtIy"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og_hyz65QVNm",
        "outputId": "ae96e9d9-5ba6-4155-e07d-d60c45162206",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.layers # Capas de la funcional"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7fb97ad55cd0>,\n",
              " <keras.layers.core.dense.Dense at 0x7fb97ad55fd0>,\n",
              " <keras.layers.core.dense.Dense at 0x7fb97ae39910>]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMvVKvM4__S5"
      },
      "source": [
        "new_output = model.layers[1]\n",
        "model_2 = keras.Model(inputs=input_layer, outputs=new_output.output)\n",
        "model_2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikT3CbfyZKC8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "47334dbd-c7ee-476c-e955-0d732f46a06e"
      },
      "source": [
        "plot_model(model)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfELBMfOCD4A",
        "outputId": "b9bc75f2-1d2e-4ddf-dee9-baf9dfa1539c"
      },
      "source": [
        "model_2.predict(X_test).shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh5-fozOCiNE"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "Generad nuevos modelos que tengan como salida las capas intermedias de vuestro modelo funcional anterior. Realizad análisis dimensional sobre las salidas de las capas anteriores y comprobad si son las dimensiones correctas de esa capa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuchreSTChhb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1OSaLDsCf6y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}